\documentclass[sigconf]{acmart}
\usepackage{booktabs} % For formal tables
\usepackage{graphicx}
\usepackage{CJKutf8}
\usepackage{multirow}

\begin{document}
\title{Towards Silver-tongued Selling: Product Snippet Generation for Consumption Scene Queries}

\author{Submission }


\begin{abstract}
In the e-commerce environment, it is a personalized service to recommend suitable products according to the shopping scene of the user. We hope to provide users with an explainable and persuasive recommendation reason when recommending products, that is, why they should recommend this product, and motivate online purchasers to make successful purchases through persuasive descriptions. In this contribution we present our system by combinning weak supervision frame with generate model.  We first select the persuasive sentences from corpus as the training data of our generate model through weak supervision. Then through our proposed model yield persuasive sentence. We conduct comprehensive experiments on real sets. Compared with state-of-the-art methods, our framework produces sentences with higher ROUGE and BLEU scores and more attractive and persuasive.

\end{abstract}

\keywords{persuasive, explainable recommendation, text generation}


\maketitle

\section{INTRODUCTION}
%background
No behavior on earth is more human than selling.
Ever since the dawn of economy, salespeople has played a pivotal role in matching customer needs with appropriate products. 
We have seen, in history, many vivid examples of top salesperson who single-handedly builds a business empire.
Having a strong sales team is crucial to the success of a company. 
This brings an interesting yet challenging question: \textit{ Can a machine function like a skilled salesperson?} 

%motivation
The first step to replace the sales department in E-commerce platforms is to mimic the sales presentation that connects products and consumers.
This means a tailored message for each product to the consumers from their specific context. 
Here the context can be interpreted as the consumption context under which the products will be utilized. 
We found many consumers like to search for products using the consumption contexts as keywords. For example, people search ``swimsuits'' with consumption context keyword ``summer vacations on beach''. 
Personalization of the message based on the target context and product is important, so that it can be affiliated to a retrieval or a recommendation system.

%problem definition
Therefore, the problem being studied in this paper is described like this.
Given a  consumption context,\footnote{We consider the context to be explicitly provided. It can also be extracted, e.g. from user profiles, which is beyond the scope of this paper.}
a product and a set of its attributes and attribute values,
our goal is to generate a natural language sentence that is 
(1) \textbf{relevant} to the consumption context, (2) \textbf{informative} about the product, (3) and organized in a \textbf{persuasive} manner.

%illustration
Figure.~\ref{fig:example} gives an illustrative example of the ideal output.
It is worthy to point out that the output satisfies three essential properties. 
It selects an arbitrary number of attributes that convey most information of the product,
and transform their values in an expression that achieves maximal relevance to the consumption context. 
Finally, the power of persuasion is enhanced by a catchy and appealing sentence that is enjoyable to read.

%related work
The problem falls in the broad class of language generation from data. Recently, end-to-end neural frameworks~\cite{Wiseman2017Challenges,Yang2017Reference,Lebret2016Neural,Karpathy2015Deep} have shown promising progress in this field. End-to-end frameworks have the advantage that errors do not accumulate across separate stages, i.e. in choosing the appropriate attributes and expressing the attribute values. However, neural frameworks require massive training data. Since we emphasize particularly on relevance and persuasiveness, we face a major challenge of  insufficient training data. We notice that there is an emerging trend in studying persuasive systems, including a recent work on writing persuasive product descriptions in fashion domain~\cite{munigala2018persuaide}. While their work is the most similar to ours, due to the same data scarcity problem, they propose an unsupervised framework and the performance is secondary.

%data level solution
%data level 
To address the insufficiency of training data, \textbf{at the data level}, we turn to a framework with weak supervision. 
Weak supervised learning implement unsupervised models or/and manually constructed heuristics on unlabelled data.
When it comes to labeling persuasive sentences, there is no sophisticated  unsupervised model to discriminate persuasive and non-persuasive text. 
In order to generate a set of rules that cover a considerably large number of possible variations, we use external data sources (i.e. blogs and advertisements) to discover syntactic sequential rules and features for persuasive texts.

%model level
Weak supervision is inherently incomplete and inaccurate.
Furthermore we should solve the structural dependency between item attributes and consumption context. Some attributes are universally perceived to be persuasive while others are attractive only under specific contexts. For example, given a swimsuit, being ``high quality and cheap'' is good despite of any context, , having. ``a low neckline'' under context ``summer beach'' is good, under context ``swim competition'' is bad. 
Therefore, \textbf{at the model level}, we embed a global-local component for skew attribute-context distribution, and a copying component for out-of-vocabulary references.

Our solution \textbf{at the knowledge level} is to incorporate knowledge to understand high-level themes of a consumption context. 
We experiment with different knowledge representations extracted from data sources other than the training data (i.e. from search logs in our E-commerce platforms).
Thus our knowledge-rich framework summarizes the connection between consumption needs and products at different granularities, which further dispose of the data scarcity problem.

\begin{figure*}\label{fig:example}
  \caption{An illustrative example}
  \label{table:example}
  \begin{tabular}{p{8cm} p{8cm}}
    \toprule
    Input: item profile wooden bookcase,scene modern house decor & input: item profile wooden bookcase,scene luxury house decor \\
    \midrule
    \begin{CJK*}{UTF8}{gbsn}
        一款\textcolor{blue}{现代}简约木质书架，采用\textcolor{red}{经典的原木设计}，由原生态\textcolor{red}{木材拼接}而成，成就了\textcolor{red}{天然原木触感}，\textcolor{red}{绿色环保}，\textcolor{red}{功能多样}，满足您不同的\textcolor{blue}{收纳需求}，让您的家\textcolor{blue}{整洁}漂亮。
    \end{CJK*} & 
    \begin{CJK*}{UTF8}{gbsn}
        这款书架采用\textcolor{red}{好实木}打造，选用天然原木，\textcolor{red}{品质优良}，\textcolor{red}{坚固耐用}。没有过多修饰的装饰，\textcolor{red}{奢华}而不张扬，更彰显了\textcolor{blue}{不凡的品味}。 
    \end{CJK*}\\
    A \textcolor{blue}{modern} and simple wooden bookcase with a \textcolor{red}{classic log design}, made of original \textcolor{red}{wood spliced}, which makes the \textcolor{red}{ natural wood touch}, \textcolor{red}{environmental friendly}, \textcolor{red}{versatile} to meet your different \textcolor{blue}{storage needs}, so that your home is \textcolor{blue}{neat} and beautiful.  &
    This bookcase is made of solid wood and is made of\textcolor{red}{ natural logs}. It is of \textcolor{red}{ high quality and durable}. There is no too much decoration, \textcolor{red}{luxury} without being ostentatious, shows the \textcolor{blue}{extraordinary taste}.\\
    \bottomrule
\end{tabular}
\end{figure*}

%related work

%contribution
Our contributions are three folds.
\begin{itemize}
\item We study a novel problem of generating persuasive, relevant and informative product snippet for different consumption contexts. As this process is highly creative and cognitive, it will beneficial for other AI topics. For example, snippet generation is the first step, which can be later extended to negotiation.
\item We present data-level, model-level and knowledge-level solutions to handle with the problem of insufficient training data.
\item We design and present a set of novel experimental scheme as well as some easy-to-implement merits to evaluate the effectiveness of our system. 
\end{itemize}


%paper structure
This paper is organized as follows. We introduce the related work in Sec.~\ref{sec:related}. In Sec.~\ref{sec:architecture}, we first introduce the architecture of our system and describe the weak supervision and our global-local-copy model. We present and analyze the experimental results on a real data set in Sec.~\ref{sec:experiment}. We conclude our work and suggest future directions in Sec.~\ref{sec:conclusion}.

\section{RELATED WORK}\label{sec:related}
We briefly survey two lines of research related to our work, language generation and learning with weak supervision.

\subsection{Language Generation}
Natural Language Generation (NLG) task has always been one of the most widely studied problems in the area of natural language processing. in particular,  we identify two types of NLG tasks: data-to-document generation and creative text generation.

\textbf{Data-to-document generation} is a classic NLG task. Given some structured data, such as a table, data-to-document generation task is to produce text, such as a sentence or a paragraph, that adequately and fluently describes the input data. Applications of data-to-document generation techniques include automatically generating product review~\cite{dong2017learning,Costa2018Automatic}, game report~\cite{Wiseman2017Challenges}, dialogues~\cite{Yang2017Reference}, biography~\cite{Lebret2016Neural}, and captioning an image ~\cite{Karpathy2015Deep}.

Early systems usually consist of two separate stages: a content selection stage to decide ``what to say'', and a  surface realization stage to decide ``how to say''.  The recent success of Deep Neural Network (DNN) models~\cite{Sutskever2011Generating} has galvanized research on end to end systems that blur the distinction between the two stages. Most of the DNN systems employ an encoder-decoder framework. Frequently adopted encoders include Multi-Level Perception (MLP)~\cite{dong2017learning,Wiseman2017Challenges,Bao2019Text} or a hierarchical form of LSTM~\cite{Yang2017Reference}. Copying is considered to be effective to manage out-of-vocabulary table references. For example,  
several copying mechanism are compared in~\cite{Bao2019Text, Wiseman2017Challenges}. Beyond simple copying, refer to a referent using varied mention forms is additionally studied in~\cite{Yang2017Reference}. After a template text with data slots is generated,  a delayed copy mechanism is proposed in ~\cite{Li2018Point} to fill in the slots with proper data records.   In the decoder layers, RNN~\cite{Wiseman2017Challenges} and LSTM~\cite{Yang2017Reference} are common choices. 
Other network structure may replace the encoder-decoder framework as the method of choice. For example, a feed-forward neural language model with attention based word copying is presented in~\cite{Lebret2016Neural} which takes aggregated word and table embeddings as input. 

From a commercial point of view, \textbf{creative text generation} tasks have received considerably more attention. In these tasks, the generated text must reveal more human characteristics. 
Applications of creative text generation include computational humor (i.e. joke recognition~\cite{kiddon2011double} and pun generation \cite{valitutti2013let}), poetry generation (i.e. Chines poetry generation~\cite{wang2016chinese,Zhang2014Chinese} and English poetry generation~\cite{Ghazvininejad2016Generating,Colton2012Full})
and slogan generation~\cite{tomavsic2014implementation}, and so on.

Again, DNN method is appealing when supervision is accessible. For example, most state-of-the-art research on poetry generation is based on encoder-decoder framework~\cite{Ghazvininejad2016Generating,Colton2012Full,wang2016chinese,Zhang2014Chinese}.
However, training collections is difficult to obtain for other types of creative text, due to the inherent complexity of cognitive process. 
In this case, unsupervised method has become the main stream method.
Most of them are heavily dependent on syntactic templates, e.g. word substitution~\cite{valitutti2013let,ozbal2013brainsup} and can only generate short headline style sentences or slogans. 
A recent work~\cite{munigala2018persuaide} explores the possibility of generating a complete persuasive sentence by an unsupervised approach.

To summarize, there are fruitful results yielded by NLG results, however, our work is different from existing work on the following two aspects. (1) While most NLG tasks focus on the output's fluency and fidelity to references, we emphasize on the persuasiveness and relevance of the output.  This is because our system aims to maximize user experience in the E-commerce ecosystem. In a sense, our system resembles post-hoc explainable recommendation systems, i.e.  systems that provide explanations which are not generated by the recommendation model itself. This type of explanations can greatly improve the degree of system effectiveness, persuasiveness, efficiency and satisfaction~\cite{Tintarev2011Designing}. Generating explanations in natural language is still in its initial phase. (2) End-to-end DNN models require large amounts of training data to obtain promising results. When it is impossible to generate labeled corpus, creative text generation systems often resort to unsupervised approaches. Our work attempts to exploit the superior learning power of DNNs by utilizing weak supervisions.

\subsection{Weak Supervision}
Supervised learning is firmly established as a standard technology across all machine learning related tasks when labelled ground truth is available. However, labelling is a labor costly procedure. To address the data scarcity issue, Recently, a significant amount of research has been proposed that aims to utilize weak supervision, which is the opposite of strong supervision~\cite{Zhou2018brief}. The collection of weak supervision can be obtained by either an unsupervised (and possibly worse performing) model, or a set of manually constructed heuristics. Examples of the former category includes training a fully feedforward NN model for information retrieval on documents labeled by a simple ranking model such as BM25~\cite{Dehghani2017Neural}. Examples of the latter category includes generating training sets by aggregating expert-derived rules~\cite{ratner2017snorkel}. 

As weak supervision are often 
incomplete (i.e. only a small fraction of training set is labelled), inexact (i.e. only coarse-grained labels are given), and/or inaccurate (i.e. given labels are not always correct), model adaptions are necessary to optimize performance. However, this is not fully explored in the DNN literature, especially for natural language generation. Most previous works simply 
treat weak supervision signals as labels. 

\section{SYSTEM ARCHITECTURE}\label{sec:architecture}
We take the corpus of product as the input of our system, and produces a persuasive sentence with the scene description of the product. Fig.~\ref{fig:system-architecture} shows an overview of the proposed system architecture with two major steps: (1) Given the corpus of product,the first step is to select the persuasive sentences as the training data of our model, (2) identify the scene name, product name, cpv data \footnote{Cpv is a collection of values of the attributes of the product. Here, only the value of the product attributes is in the sentence it can be extracted.} from the selected sentence as the input of our model,then yield persuasive sentence. In this section, we first introduce the weak supervision method for selecting the persuasive sentences. We then present our global-local-copy model in detail.  

\begin{figure}
    \centering
    \includegraphics[width=8cm,height=5cm]{system-architecture.jpg}
\caption{System Architecture}\label{fig:system-architecture}
\end{figure}

\subsection{Resources Used}
% Data set
We use the list of product recommendation reasons as our dataset. The corpus are generated by high quality person.But the quality of the original dataset is far from ideal, there are many recommended reasons are even the original title of the product, so we need to filter the training data.

\subsection{Weak Supervision}
% Weak Supervision
Manual labeling is very time consuming, so we use the Snorkel \cite{ratner2017snorkel} weak supervision method to mark the data without the user to manually mark any training data. Rather than hand-labeling training data, users of Snorkel write labeling functions(LF), which allow them to express various weak supervision sources such as patterns, heuristics, external knowledge bases, and more. We wrote ten labeling functions based on the characteristics of persuasive sentences, is shown in Tab.~\ref{table:LF}. Among them, the labels of the first five functions are positive and the rest are negative.

\begin{table}
  \caption{Labeling Functions}
  \label{table:LF}
  \begin{tabular}{p{2.5cm}p{5cm}}
    \toprule
    Labeling Functions & Description\\
    \midrule
    %正类
    is\_neat & Sentence is neat\\
    has\_modal & Sentence has modal particle\\
    four\_word & Sentence contains a four-word structure \\
    dot\_word & The comma is followed by
        \begin{CJK*}{UTF8}{gbsn}
            "让/使/为/给"
        \end{CJK*}
        or verbs\\
    end\_exclamation & Sentence ends with an exclamation point\\
    %负类
    no\_adj\_and\_adv & Sentence has no adjectives and adverbs\\
    other\_words & Sentence contains characters other than Chinese, English, numbers, and specified symbols
        \begin{CJK*}{UTF8}{gbsn}
            (。，？！、；：).
        \end{CJK*}\\
    tree\_depths & the depth of the dependency tree is greater than 10\\
    clause\_num & the number of clauses is greater than 10\\
    token\_num & the number of word segments is greater than 10\\
  \bottomrule
\end{tabular}
\end{table}

Next, Snorkel automatically learns a generative model over the labeling functions,the output of Snorkel is a set of probabilistic labels. The statistics about the resulting label matrix is shown in Tab.~\ref{table:LabelMatrix}. \textbf{Coverage} is the fraction of candidates that the labeling function emits a non-zero label for. \textbf{Overlap} is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a non-zero label for. \textbf{Conflict} is the fraction candidates that the labeling function emits a non-zero label for and that another labeling function emits a conflicting non-zero label for. We choose sentences with probabilistic labels are bigger than 0.5 and the words are less than 50 as the training set of our model.

\begin{table}
  \caption{Statistics about the resulting label matrix}
  \label{table:LabelMatrix}
  \begin{tabular}{p{2cm}p{1.5cm}p{1.5cm}p{1.5cm}}
    \toprule
    LFs & Coverage & Overlaps & Conflicts\\
    \midrule
    %正类
    is\_neat & 0.075185 & 0.060664 & 0.040715\\
    has\_modal & 0.022520 & 0.019763 & 0.004743\\
    four\_word & 0.418368 & 0.333411 & 0.061301 \\
    dot\_word & 0.607374 & 0.411911 & 0.118444\\
    end\_exclamation & 0.070130 & 0.061328 & 0.010403\\
    %负类
    no\_adj\_and\_adv & 0.113256 & 0.086246 & 0.063460\\
    other\_words & 0.060238 & 0.052460 & 0.049377\\
    tree\_depths & 0.004969 & 0.004637 & 0.004564\\
    clause\_num & 0.022300 & 0.022194 & 0.022154\\
    token\_num & 0.103537 & 0.077849 & 0.056611\\
  \bottomrule
\end{tabular}
\end{table}

\subsection{Background: Transformer}
Transformer~\cite{vaswani2017attention} is a network architecture based solely on an attention mechanism, dispensing with recurrence and convolutions entirely. Transformer have an encoder-decoder structure and both the encoder and decoder are composed of a stack of $N = 6$ identical layers.

\textbf{Encoder:} Each layer has two sub-layers. The first is a multi-head self-attention mechanism, and the second is a fully connected feed-forward network.

\textbf{Decoder:} In addition to the two sub-layers in each encoder layer, the decoder inserts a third sub-layer, which performs multi-head attention over the output of the encoder stack. 


\subsection{Global-Local-Copy Model}
Global-Local-Copy model is comprised of three modules which is based on Transformer architecture. Fig.~\ref{fig:model} illustrates the detailed model structure. Global-Local-Copy model is also with encoder-decoder structure. The encoder consists of global module and local module and the copy module is in decoder part. 

Our goal is to generate persuasive sentences with scene descriptions based on the scenes, products, and attributes given by the user. In our training set, some sentences have only product descriptions, no descriptions of related scenes, and some sentences are product descriptions in different scenarios. We use a global module to learn text descriptions of all products on all texts and learn scene-specific description through local modules. We want the output sentence to contain user-supplied input, so we also add the copy module to our model.

\textbf{Encoder:} We produce a global encoding $H^{global}$ of $X$ using a global encode part of Transformer and the local encoding is $H^{local}$. The outputs of the two modules are combined through a mixture layer to yield a global-local encoding $H$ of $X$. The left of Fig.~\ref{fig:model} illustrates the global-local modules encoder. 
\begin{figure*}
    \centering
    \includegraphics[width=12cm,height=8cm]{model2.jpg}
\caption{Global-Local-Copy Model}\label{fig:model}
\end{figure*}

\begin{equation}\label{equ:mixture}
    \mathbf{H} = \beta^s\mathbf{H}^{local} + (1-\beta^s)\mathbf{H}^{global}.
\end{equation}
Here, the scalar $\beta$ is a learned parameter between 0 and 1 that is specific to the scenario $s$.

\textbf{Decoder:} The copy module is in decoder module, the probability of generating any target word $y_t$, is given by the mixture of probabilities as follows

\begin{equation}\label{equ:mixture-prob}
    p(y_t) = p(y_t,g) + p(y_t,c)
\end{equation}

where $g$ stands for the generate-mode, and $c$ the
copy mode. the right of Fig.~\ref{fig:model} illustrates the copy module decoder. $H$ is global-local encoding the above-mentioned, $\zeta(y)$ is the weighted sum of hidden states $H$ corresponding to $y$, referred to as selective read in the right of Fig.~\ref{fig:model}. 

\begin{equation}\label{equ:zeta}
    \zeta(y) = \sum^{T}_{\tau = 1} \rho_\tau \textbf{h}_\tau 
\end{equation}

\begin{equation}\label{equ:rho}
    \rho_\tau = \left\{
        \begin{aligned}
        \frac{1}{K} p(x_\tau,\textbf{c}|\textbf{H}), \quad & x_\tau = y_t & \\
        0, \quad & otherwise &
        \end{aligned} 
        \right.
\end{equation}

where $K$ is equal to the number of positions with source keywords in the target sentence, $\tau$ is the index of source keywords, $T$ is the number of keywords, $t$ is the index of word in target sentence, and $p(x_\tau,\textbf{c}|\textbf{H})$ is the probability of the source keyword be copied in target sentence. 

The score of each mode is calculated:

\textbf{Generate-Mode}: first connect the output of the feed forward part of the transformer method and selective-read, and then $p(y_t,g)$ is calculated through the full connection. 

\textbf{Copy-Mode}: first calculate $\sigma(\textbf{H}\textbf{W})$, $\sigma$ is a non-linear activation function, here using the $tanh$ function. Next $p(y_t,c)$ is calculated through the full connection. 

\section{EXPERIMENTAL SETUP}\label{sec:experiment}
\subsection{Dataset}
In this paper,we focus on two sub-scenarios under the home: creative home and simple home. We select the description of the products in these two scenarios from the list of product recommendation reasons. We collected 150,743 sentences related to these products, after weak supervision, left 103,612 sentences. We chose sentences which keyword input only appears once as the test set. Training data format is shown in Tab.~\ref{table:format}. 

\begin{table}
\caption{Training data format }\label{table:format}
\begin{center}
\begin{tabular}{p{2.5cm}p{5cm}}
    \toprule
    Input & Output \\
    \midrule
    \begin{CJK*}{UTF8}{gbsn}
        创意，纸巾盒，欧式
    \end{CJK*} &
    \begin{CJK*}{UTF8}{gbsn}
        一款欧式风范榉木纸巾盒，盒身采用创意撞色设计，不仅能放杂物，还能作为桌面摆设，大中小三种尺寸可选，适合多种场合使用。
    \end{CJK*} \\
    \bottomrule
\end{tabular}
\end{center}
\end{table}

\subsection{Comparative Method}
%WWW这篇有一步寻找名词短语，我的替换方法是 形容词（1个或多个）+ 的 + 名词（0个或1个） 例如： 浪漫的荷花  这样子的词语
%None Phrase Selection部分，改成寻找【形容词（1个或多个）+ ‘的’ + 名词（0个或1个）】的短语，因为文中没有提到KeywordExpansion部分的k和None Phrase Selection部分的L取值，我就选了k=5和l=10，其他都和文中一样

\subsection{Training}
We take the words from source side of corpus as the input vocabulary and chose the words from target side of corpus which word frequency greater than 20 as the output vocabulary. The dimension of word embedding and hidden units are both 512,the minibatch was set to be 64. The parameter of global-local module $\beta$ is initialized by 0.5, the parameter $W$ in copy module is randomly initialized and the the parameter $p$ is initialized by zero.

\subsection{Evaluation}
There are no direct evaluation metrics so that evaluate text generation system is difficult.  We choose ROUGE \cite{lin2004rouge} and BLEU \cite{papineni2002bleu} metrics that are popularly used for generation tasks (especially Machine Translation and Summarization). These two metrics are both based on references, but there are thousands of ways to generate an appropriate sentence for a specific product,the limited references are impossible to cover all the correct results. So,we we use five evaluation standards for human evaluators to check the quality of the generated descriptions on a small test dataset of 30 instances. The manual evaluation metrics are listed in Tab.~\ref{table:evaluation}. The score of each manual evaluation metrics ranges from 0 to 5 with the higher score the better, see Tab.~\ref{table:evaluation-rule} for more detailed Grading Rules. All the generated sentences are evaluated by 5 experts and the rating scores are averaged as the final score.

\begin{table}
\caption{Manual Evaluation }\label{table:evaluation}
\begin{center}
\begin{tabular}{p{2.5cm}p{5cm}}
    \toprule
    Evaluation Metric & Description \\
    \midrule
    Fluency \cite{wang2016chinese} & Does the sentence read smoothly and fluently? \\
    Catchyness \cite{munigala2018persuaide} & Is the description attractive,catchy? \\
    Relatedness \cite{munigala2018persuaide} & Is the description semantically related to the target scene? \\
    Completeness & Is the description contains the corresponding scene, product and attribute? \\
    Informative & Is the description informative?\\
    \bottomrule
\end{tabular}
\end{center}
\end{table} 

\begin{table}
\caption{Manual Evaluation details}\label{table:evaluation-rule}
\begin{center}
\begin{tabular}{p{2.5cm}p{1cm}p{4.5cm}}
    \toprule
    Evaluation Metric & Score & Description \\
    \midrule
    \multirow{3}*{Fluency} & 0 & Not at all smooth \\
    ~ & 1-4 & how many places are not smooth minus how many points \\
    ~ & 5 & Very smooth\\
    \hline
    Catchyness & 0-5 & The ratio of attractive words in total words multiply by 5\\
    \hline
    \multirow{4}*{Relatedness} & 0 & Completely unrelated to the scene \\
    ~ & 1 & none \\
    ~ & 2 & Refer to the scene \\ 
    ~ & 3-5 & how many descriptions related to the scene, add how many points\\
    \hline
    \multirow{6}*{Completeness} & 0 & No input at all \\
    ~ & 1 & none \\
    ~ & 2 & Contains an input keyword \\ 
    ~ & 3 & Contains two input keyword\\
    ~ & 4 & There's no third word involved, but it's relevant\\
    ~ & 5 & Completely contains\\
    \hline
    \multirow{3}*{Informative} & 0 & No information at all \\
    ~ & 1 & It's describing the product \\
    ~ & 2-5 & how much information about the product, add how many points\\
    \bottomrule
\end{tabular}
\end{center}
\end{table} 

\subsection{Results}
We report the experimental results for our two approaches, i.e. global-local model and global-local-copy model. The difference between two models is former has no copy module. We compare our models with the Transformer method. Results are reported on the test data of 1472 instances, used for automatic evaluation and a held-out set of 32 instances, used for manual evaluation. The source keyword of test data for automatic evaluation are never appeared in train data. We choose the source keyword of test data that have scene name, product name and only one cpv value for manual evaluation.

From the perspective of considering our system as another machine translation system that converts some keywords of product(the scene name, product name, cpv data) into a persuasive product description with scene, we have results shown in Tab.~\ref{table:evaluation-automatic}. Popular machine translation and summarization metrics BLEU and ROUGE are used. There are four different ROUGE measures: ROUGE-N, ROUGE-L, ROUGE-W, and ROUGE-S, depending on the textual units to be compared. As can be seen from the results, our two methods are superior to Transformer in every indicator. Explain that both the global-local module and the copy module have a positive impact on the model. Because these two metrics are both based on references, and the copy module is aim to let the output sentence contain user-supplied input, so the results of global-local-copy model is better than global-local model.

\begin{table}
  \caption{Automatic Evaluation Metrics}
  \label{table:evaluation-automatic}
  \begin{tabular}{c c c c}
    \toprule
    Metrics & Transformer & Global-local & Global-local-copy\\
    \midrule
    ROUGE-1 & 0.3933 & 0.4050 & 0.4054\\
    ROUGE-2 & 0.1319 & 0.1446 & 0.1488\\
    ROUGE-3 & 0.0643 & 0.0740 & 0.0777\\
    ROUGE-4 & 0.0424 & 0.0514 & 0.0521\\
    ROUGE-L & 0.3259 & 0.3373 & 0.3423\\
    ROUGE-W & 0.1491 & 0.1552 & 0.1585\\
    ROUGE-S* & 0.1628 & 0.1762 & 0.1784\\
    BLEU-1 & 0.2964 & 0.3056 & 0.3096\\
    BLEU-2 & 0.1556 & 0.1671 & 0.1729\\
    BLEU-3 & 0.0807 & 0.0926 & 0.0977\\
    BLEU-4 & 0.0522 & 0.0632 & 0.0654\\
  \bottomrule
\end{tabular}
\end{table}

From the perspective of human psychology of persuasive product descriptions, we manually evaluated the generated descriptions using human evaluators. Five different measures were used to evaluate the human subjectiveness: Catchyness, Relatedness, Fluency, Completeness and Informative. It can be evidently observed in Tab.~\ref{table:evaluation-manual}. that the proposed system generated more catchy, better related, more fluency sentences compared to the Transformer method. Because our global-local module focuses on the description of the scene, resulting in the generated sentences with more descriptions of the scene, more appealing and more relevant to the scene. What's more, sentences generated by our model contain more input keywords and have more information about product.

\begin{table}
  \caption{Manual Evaluation Metrics}
  \label{table:evaluation-manual}
  \begin{tabular}{c c c c}
    \toprule
    Metrics & Transformer & Global-local & Global-local-copy\\
    \midrule
    Catchyness & 1.2235 & 1.2455 & 1.3320\\
    Relatedness & 2.4375 & 2.5000 & 2.7500\\
    Fluency & 3.4375 & 3.7187 & 3.9375\\
    Completeness & 3.6250 & 3.9375 & 3.9062\\
    Informative & 3.0312 & 3.4687 & 3.4687 \\
  \bottomrule
\end{tabular}
\end{table}

For qualitative analysis, we also provide the sentences generated from our system as well as other systems in the Tab.~\ref{table:case}. As we can see, the descriptions generated by our systems are competitive or better in terms of creativity, persuasiveness and fluency than the supervised baselines but have less overlap with the reference descriptions. This explains why our system is deemed to have underperformed than the baselines, as per the automatic evaluation scores. In general, the field of creative text generation demands looking beyond simplistic evaluation measures and it is about time that trainable metrics for evaluating persuasive text holistically, including aspects on creativity, coherency, novelty are proposed.

\begin{table*}
  \caption{Sample generations from different systems along with inputs and reference descriptions}
  \label{table:case}
  \begin{tabular}{p{2.5cm}p{12cm}}
    \hline
    Input & 
    \begin{CJK*}{UTF8}{gbsn}
        创意，挂钟，奢华
    \end{CJK*} \\
    Transformer & 
    \begin{CJK*}{UTF8}{gbsn}
        创意 十足 的 挂钟 ， 舒适 静音 的 设计 ， 温柔 的 花纹 ， 灵动 而 神秘 ， 让 你 爱 坐在 客厅 的 时光 里 里 静静 享受 质量 。
    \end{CJK*} \\
    Global-local & 
    \begin{CJK*}{UTF8}{gbsn}
        创意 挂钟 ， 奢华 镶 钻 ， 奢华 镶 钻 ， 奢华 镶 钻 。
    \end{CJK*} \\
    Global-local-copy & 
    \begin{CJK*}{UTF8}{gbsn}
        创意 十足 的 大 号 挂钟 ， 奢华 范 ， 奢华 独特 。
    \end{CJK*} \\
    \hline
    Input & 
    \begin{CJK*}{UTF8}{gbsn}
        简约，挂钟，精致
    \end{CJK*} \\
    Transformer & 
    \begin{CJK*}{UTF8}{gbsn}
        简约 静音 挂钟 ， 做工 精致 ， 细节 精致 ， 高档 品质 之选 。
    \end{CJK*} \\
    Global-local & 
    \begin{CJK*}{UTF8}{gbsn}
        可 摇摆 的 静音 挂钟 ， 做工 精致 ， 造型 独特 ， 简约 大气 的 外形 符合 你 的 工作 品质 生活 ， 静音 设计 ， 增加 家中 的 灵动 性 。
    \end{CJK*} \\
    Global-local-copy & 
    \begin{CJK*}{UTF8}{gbsn}
        这 款 挂钟 ， 造型 简约 大方 ， 做工 精致 ， 散发 着 大自然 的 气息 ， 选用 的 静音 扫描 机芯 ， 走时 准确 ， 可 挂 在 墙上 ， 方便 又 不 掉色 。
    \end{CJK*} \\
  \bottomrule
\end{tabular}
\end{table*}

\section{Conclusion}\label{sec:conclusion}

\section{Acknowledgments}

\bibliographystyle{ACM-Reference-Format}
\bibliography{refer.bib}
\end{document}
